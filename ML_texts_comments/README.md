Определение токсичности комментариев
Описание проекта
Цель данного проекта - построить инструмент, который будет искать токсичные комментарии и отправлять их на модерацию в интернет-магазине.

Мы обучили модель классифицировать комментарии на позитивные и негативные на основе набора данных с разметкой о токсичности правок. Для этого мы использовали два способа: предобученную нейронную сеть BERT и модель машинного обучения CatBoost.

Стек технологий
Python
NumPy, Pandas
PyTorch, Transformers
LogisticRegression, CatBoostClassifier
tqdm, TfidfVectorizer, GridSearchCV, StratifiedKFold
DistilBertTokenizer, DistilBertConfig, DistilBertForSequenceClassification, AutoTokenizer, AutoModelForSequenceClassification
TensorDataset, Dataset, DataLoader
Результаты проекта
Мы построили инструмент, который будет искать токсичные комментарии и отправлять их на модерацию в интернет-магазине.

Мы использовали два способа для определения токсичных комментариев: предобученную нейронную сеть BERT и модель машинного обучения CatBoost. Обе модели имеют свои плюсы и минусы.

Мы получили метрику качества F1=0.752 для модели CatBoost и F1=0.85 для предобученной модели BERT.

Статус проекта
Проект находится в процессе выполнения. Планируется завершение до 09.04.2023.
